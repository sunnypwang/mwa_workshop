{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc-autonumbering": false,
    "toc-showcode": false,
    "toc-showmarkdowntxt": false,
    "toc-showtags": false,
    "colab": {
      "name": "Workshop-1.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0ulXo4ut8zt",
        "colab_type": "text"
      },
      "source": [
        "# Workshop 2-1\n",
        "\n",
        "Regression Exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyzolcnEt8zx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widget\n",
        "from ipywidgets import interact, interact_manual\n",
        "import urllib\n",
        "\n",
        "rng = np.random.RandomState(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-F4gbyFxhrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for file in ['features_rain.pk','labels_rain.pk','data1.csv','data2.csv','data3.csv']:\n",
        "    urllib.request.urlretrieve('https://github.com/sunnypwang/mwa_workshop/raw/master/' + file, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "_UDWq7dmt8z4",
        "colab_type": "text"
      },
      "source": [
        "# Part 1 - Exercise Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zvCs3XGuSmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_csv(filename, features=['x'], labels=['y']):\n",
        "    df = pd.read_csv(filename + '.csv')\n",
        "    x = df[features].to_numpy()\n",
        "    y = df[labels].to_numpy()\n",
        "    return x,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3faBox0t8z6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for filename in ['data1','data2','data3']:\n",
        "    x,y = load_csv(filename)\n",
        "    plt.title(filename)\n",
        "    plt.scatter(x, y)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPMnM8CJt80A",
        "colab_type": "text"
      },
      "source": [
        "### TODO1\n",
        "\n",
        "Describe the relationship between X and Y for each dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk5pfpAyt80C",
        "colab_type": "text"
      },
      "source": [
        "### Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFZbWTxkt80D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "\n",
        "def fit_linear(x, y):\n",
        "    linear_reg = LinearRegression()\n",
        "    linear_reg.fit(x, y)    \n",
        "    return linear_reg\n",
        "\n",
        "def predict(x, model):\n",
        "    y_pred = model.predict(x)\n",
        "    return y_pred\n",
        "\n",
        "def simple_data_wrapper(filename,show_trend=False):\n",
        "    x,y = load_csv(filename,['x'],['y']) \n",
        "    x = x.reshape(-1,1)\n",
        "    linear_reg = fit_linear(x, y)\n",
        "    y_pred = predict(x, linear_reg)\n",
        "    \n",
        "    print('m =',linear_reg.coef_)\n",
        "    print('c =',linear_reg.intercept_)\n",
        "    print('loss =',mse(y, y_pred))\n",
        "    plt.title(filename)\n",
        "    plt.scatter(x, y)\n",
        "    \n",
        "    if show_trend:\n",
        "        plt.plot(x, y_pred, '--', color='red')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkCzub6pt80J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interact(simple_data_wrapper, filename=['data1','data2','data3'], show_trend=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od0at5mht80P",
        "colab_type": "text"
      },
      "source": [
        "### TODO2\n",
        "\n",
        "Why is the regression line in data3 has slightly higher slope than it look? What is the effect of outliers?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QbN0YaSt80R",
        "colab_type": "text"
      },
      "source": [
        "# Part 2 - Real Data\n",
        "<a id='real'></a>\n",
        "\n",
        "### Precipitation Nowcasting ###\n",
        "\n",
        "Precipitation nowcasting is the the task of predicting the amount of rainfall in a certain region given some kind of sensor data.  The term nowcasting refers to tasks that try to predict the current or near future conditions (within 6 hours). \n",
        "\n",
        "You will be given satellite images in 3 different bands covering a 5 by 5 region from different parts of Thailand. In other words, your input will be a 5x5x3 image. Your task is to predict the amount of rainfal in the center pixel. You will first do the prediction using just a simple fully-connected neural network that view each pixel as different input features.\n",
        "\n",
        "Since the your input is basically an image, we will then view the input as an image and apply CNN to do the prediction. Finally, we can also add a time component since weather prediction can benefit greatly using previous time frames. Each data point actually contain 5 time steps, so each input data point has a size of 5x5x5x3 (time x height x width x channel), and the output data has a size of 5 (time). You will use this time information when you work with RNNs.\n",
        "\n",
        "Finally, we would like to thank the Thai Meteorological Department for providing the data for this assignment.\n",
        "\n",
        "### Data Explanation\n",
        "\n",
        "The data is an hourly measurement of water vapor in the atmosphere, and two infrared measurements of cloud imagery on a latitude-longitude coordinate. Each measurement is illustrated below as an image. These three features are included as different channels in your input data.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/burin-n/pattern-recognition/master/HW4/images/wvapor.png\" width=\"200\"> <img src=\"https://raw.githubusercontent.com/burin-n/pattern-recognition/master/HW4/images/cloud1.png\" width=\"200\"> <img src=\"https://raw.githubusercontent.com/burin-n/pattern-recognition/master/HW4/images/cloud2.png\" width=\"200\">\n",
        "\n",
        "We also provide the hourly precipitation (rainfall) records in the month of June, July, August, September, and October from weather stations spreaded around the country. A 5x5 grid around each weather station at a particular time will be paired with the precipitation recorded at the corresponding station as input and output data. \n",
        "\n",
        "**features** \n",
        "- dim 0: number of entries\n",
        "- dim 1,2: a 5x5 grid around rain-measued station\n",
        "- dim 3: water vapor and two cloud imagenaries \n",
        "\n",
        "**labels**\n",
        "- dim 0: number of entries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_-P-rdJt80S",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKyqaWXCt80U",
        "colab_type": "text"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTV1_9vKt80V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_raw = pickle.load(open('features_rain.pk','rb'))\n",
        "y_train_raw = pickle.load(open('labels_rain.pk','rb'))\n",
        "print('x_train shape:',x_train_raw.shape)\n",
        "print('y_train shape:', y_train_raw.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EvSx4POt80a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = ['vapor','infrared-1','infrared-2']\n",
        "for i in range(3):\n",
        "    plt.hist(x_train_raw[:,:,:,i].mean(axis=(1,2)))\n",
        "    plt.title(features[i])\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnasaNJvt80e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.heatmap(x_train_raw[0,:,:,0],annot=True,fmt='.2f',square=True,cmap=\"YlGnBu\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXvuKat8t80j",
        "colab_type": "text"
      },
      "source": [
        "### Linear Regression with single feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aCxJ3MCt80k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "def normalizer(x):\n",
        "    return StandardScaler().fit_transform(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sHuepaft80q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def real_data_wrapper(feature,show_trend=True,normalize=False):\n",
        "\n",
        "    x = x_train_raw[:,2,2,feature_list[feature]].reshape(-1,1)\n",
        "    if normalize:\n",
        "        x = normalizer(x)\n",
        "    \n",
        "    y = y_train_raw\n",
        "    \n",
        "    linear_reg = fit_linear(x, y)\n",
        "    y_pred = predict(x, linear_reg)\n",
        "    \n",
        "    print('m =',linear_reg.coef_)\n",
        "    print('c =',linear_reg.intercept_)\n",
        "    print('loss =',mse(y, y_pred))\n",
        "\n",
        "    plt.scatter(x, y)\n",
        "    if show_trend:\n",
        "        plt.plot(x, y_pred, '--', color='red')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('rainfall')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1X4kPBst80u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_list = {'vapor':0,'infrared-1':1,'infrared-2':2}\n",
        "feat_idx = widget.widgets.Dropdown(options=feature_list.keys(),description='Feature')\n",
        "interact_manual(real_data_wrapper,feature=feat_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-X-X9_wt80y",
        "colab_type": "text"
      },
      "source": [
        "### Linear Regression with multiple features (multivariable linear regression)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovzzpCi1t800",
        "colab_type": "text"
      },
      "source": [
        "Let's use all three features (vapor, latitude, longitude)\n",
        "\n",
        "Note that we are now solving a equation beyond 2D space, so we cannot draw a scatter plot as before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtsiOMATt801",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train_raw[:,2,2]\n",
        "y_train = y_train_raw\n",
        "\n",
        "print('x_train shape:',x_train.shape)\n",
        "print('y_train shape:', y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trTKZFpUt806",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear_reg = fit_linear(x_train, y_train)\n",
        "y_pred = predict(x_train, linear_reg)\n",
        "\n",
        "print('m =',linear_reg.coef_)\n",
        "print('c =',linear_reg.intercept_)\n",
        "print('loss =',mse(y_train, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPuI2kYrt81C",
        "colab_type": "text"
      },
      "source": [
        "Let's use the surrounding values in a 5x5 grid as features as well.\n",
        "\n",
        "Right now there are 5 * 5 * 3 = 75 features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50PQLyMTt81E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train_raw.reshape(-1,75)\n",
        "y_train = y_train_raw\n",
        "\n",
        "print('x_train shape:',x_train.shape)\n",
        "print('y_train shape:', y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvH-Utsrt81H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear_reg = fit_linear(x_train, y_train)\n",
        "y_pred = predict(x_train, linear_reg)\n",
        "\n",
        "print('m =',linear_reg.coef_)\n",
        "print('c =',linear_reg.intercept_)\n",
        "print('loss =',mse(y_train, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzyJ5EdVt81L",
        "colab_type": "text"
      },
      "source": [
        "Notice that the loss is roughly the same. What does this mean?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfMBbVzit81N",
        "colab_type": "text"
      },
      "source": [
        "### Other Linear Regression\n",
        "\n",
        "Recall that the loss function of simple linear regression is ordinary least squares (OLS)\n",
        "$$loss = \\sum (y - \\hat{y})^2$$\n",
        "\n",
        "However, OLS is unbiased, meaning that it treats all features with the same level of importance. In reality, you would only focus on most important features and discard unrelated features. OLS also suffer from multicolinearity of the dataset.\n",
        "\n",
        "Ridge regression is a variant of linear regression that addresses these problems by introducing a penalty term to the loss function. This penalty term will help to reduce the sum of coefficients to reduce the weight of unimportant features. This is known as L2 regularization.\n",
        "The loss function of ridge regression is given by\n",
        "$$loss = \\sum (y - \\hat{y})^2 + \\lambda \\sum \\beta^2 $$\n",
        "\n",
        "Lasso regression is another variant of linear regression that use L1 regularization as a pernalty term instead.\n",
        "$$loss = \\sum (y - \\hat{y})^2 + \\lambda \\sum |\\beta| $$\n",
        "\n",
        "Elastic Net regression is another variant of linear regression that combine L1 and L2 regularization together as a penalty term. In other words, elastic net method includes the lasso and ridge regression. $r$ is determines the ratio between L1 and L2 regularization.\n",
        "$$loss = \\sum (y - \\hat{y})^2 + \\big{(}r * \\lambda_1\\sum |\\beta|\\big{)} + \\big{(}(1-r) * \\lambda_2\\sum \\beta^2\\big{)}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SHEFF4jt81O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train_raw.reshape(-1,75)\n",
        "y_train = y_train_raw\n",
        "\n",
        "print('x_train shape:',x_train.shape)\n",
        "print('y_train shape:', y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvS88dQ4t81S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import Ridge,Lasso,ElasticNet\n",
        "\n",
        "def models_wrapper(method='linear',normalize=False):\n",
        "\n",
        "    x = x_train\n",
        "    y = y_train\n",
        "    \n",
        "    if normalize:\n",
        "        x = normalizer(x)\n",
        "    \n",
        "    if method == 'ridge':\n",
        "        model = Ridge()\n",
        "    elif method == 'lasso':\n",
        "        model = Lasso()\n",
        "    elif method == 'elastic':\n",
        "        model = ElasticNet()\n",
        "    else:\n",
        "        model = LinearRegression()\n",
        "        \n",
        "    print('Model used :',method)\n",
        "    model.fit(x,y)\n",
        "    y_pred = predict(x, model)\n",
        "    \n",
        "    print('m =',linear_reg.coef_)\n",
        "    print('c =',linear_reg.intercept_)\n",
        "    print('loss =',mse(y, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1QE257ct81W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interact_manual(models_wrapper,method=['ridge','lasso','elastic','linear'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCAmqxQDt81b",
        "colab_type": "text"
      },
      "source": [
        "<a id='real_logistic'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpGapTKLt81c",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z2evptOt81d",
        "colab_type": "text"
      },
      "source": [
        "ในส่วนของการทำ Logistic Regression นั้นจะใช้ในโจทย์ประเภท Classification ซึ่งจะใช้ label เป็นคลาสต่างๆ โดยเป้าหมายของ Classification Problem คือ ทำนายว่าจะมีโอกาสเป็นคลาสไหนมากที่สุด แทนที่จะทำนายว่ามีปริมาณเท่าไหร่ ดังนั้นจึงต้องแปลงผลเฉลยจากตัวเลขให้เป็นคลาสที่แตกต่างกัน โดยจะกำหนดให้\n",
        "\n",
        "เมื่อไม่มีปริมาณน้ำฝนเลย เป็นคลาส 0 (ฝนไม่ตก)\n",
        "\n",
        "เมื่อมีปริมาณน้ำฝนไม่ว่าเท่าใดก็ตาม เป็นคลาส 1 (ฝนตก)\n",
        "\n",
        "**ดังนั้นโจทย์ของ Logistic Regression คือ ให้ทำนายว่ามีฝนตกหรือไม่**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fST5XX5Lt81e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train_raw.reshape(-1,75)\n",
        "y_train = (y_train_raw > 0).astype(int)\n",
        "\n",
        "print('x_train shape:',x_train.shape)\n",
        "print('y_train shape:', y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTTKx3b7t81i",
        "colab_type": "text"
      },
      "source": [
        "#### Explore Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfLrCS35t81k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def class_hist(y,labels=None):\n",
        "    n,b = np.histogram(y,bins=2,range=(0.,1.))\n",
        "    print(n)\n",
        "    plt.pie(n,labels=labels,autopct='%1.1f%%')\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OmC8CL7t81o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_hist(y_train,labels=['not rain', 'rain'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roPnYKaft81t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "def evaluate(y_true,y_pred):\n",
        "    acc = accuracy_score(y_true,y_pred)\n",
        "    p = precision_score(y_true,y_pred)\n",
        "    r = recall_score(y_true,y_pred)\n",
        "    \n",
        "    print('Accuracy : {:.3f}'.format(acc))\n",
        "    print('Precision : {:.3f}'.format(p))\n",
        "    print('Recall : {:.3f}'.format(r))\n",
        "    \n",
        "def logistic_wrapper(penalty='l2',max_iter=100,C=1):\n",
        "    solver = None\n",
        "    if penalty == 'l1':\n",
        "        solver = 'liblinear'\n",
        "    elif penalty == 'l2':\n",
        "        solver = 'lbfgs'\n",
        "    else:\n",
        "        solver = 'saga'\n",
        "    \n",
        "    x = normalizer(x_train)\n",
        "    y = y_train\n",
        "    \n",
        "    print('Running...')\n",
        "    logistic_reg = LogisticRegression(penalty=penalty,solver=solver,max_iter=max_iter,C=C)\n",
        "    logistic_reg.fit(x,y)\n",
        "    \n",
        "    y_pred = predict(x, logistic_reg)\n",
        "    evaluate(y, y_pred)\n",
        "    \n",
        "    plot_confusion_matrix(logistic_reg, x, y)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjnrNplqt81y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "penalty_widget = widget.widgets.Dropdown(options=['l1','l2','elasticnet'],value='l2')\n",
        "max_iter_widget = widget.widgets.IntSlider(value=100,min=100,max=1000,step=50)\n",
        "C_widget = widget.widgets.FloatLogSlider(value=1,min=-5,max=0,step=1,readout_format='.0e')\n",
        "interact_manual(logistic_wrapper,penalty=penalty_widget,max_iter=max_iter_widget,C=C_widget)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TktobtYyt813",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}